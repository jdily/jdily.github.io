<!DOCTYPE html>
<!--[if lt IE 8 ]><html class="no-js ie ie7" lang="en"> <![endif]-->
<!--[if IE 8 ]><html class="no-js ie ie8" lang="en"> <![endif]-->
<!--[if (gte IE 8)|!(IE)]><!-->
<html class="no-js" lang="en">
<!--<![endif]-->

<head>

    <!--- Basic Page Needs
   ================================================== -->
    <meta charset="utf-8">
    <title>I-Chao Shen</title>
    <meta name="description" content="">
    <meta name="author" content="">

    <!-- Mobile Specific Metas
   ================================================== -->
    <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">

    <!-- CSS
    ================================================== -->
    <link rel="stylesheet" href="css/default.css">
    <link rel="stylesheet" href="css/layout.css">
    <link rel="stylesheet" href="css/media-queries.css">
    <link rel="stylesheet" href="css/magnific-popup.css">
    <!-- <link rel="stylesheet" href="css/academicons.min.css"> -->
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons/css/academicons.min.css">


    <!-- Script
   ================================================== -->
    <script src="js/modernizr.js"></script>

    <!-- Favicons
	================================================== -->
    <link rel="shortcut icon" type="image/png" href="./images/ichao_potrait.png">

</head>

<body>

    <!-- Header
   ================================================== -->

    <!-- Style Guide Section
   ================================================== -->
    <section id="styles" style="background: #fff;">
        <br>

    <div class="row about">	
        <div class="two columns">
            <img src="./resource/ichao_photo.JPG" width="80%" alt="" align="middle" style="padding-top: 20px;"/>
        </div>
        <!-- <div class="two columns">
            
        </div> -->
        <div class="ten columns">
            <a style="float: right" href="./index_j.html">[Japanese]</a>
            <h3>I-Chao Shen</h3>
            <h6>ichaoshen@g.ecc.u-tokyo.ac.jp</h6> 
            <p>
                I am an assistant professor (助教) at the Graduate School of Information Science and Technology, the University of Tokyo. 
                I am a member of the <a href="http://www-ui.is.s.u-tokyo.ac.jp/en/">User Interface Research Group</a> and working with <a href="https://www-ui.is.s.u-tokyo.ac.jp/~takeo/">Takeo Igarashi</a>.
                My research focus on human-guided optimization, where I explore combinations between different human priors and numerical optimization 
                and develop supportive system for visual content design.
                <br>
                <i class="ai ai-cv-square ai-1x"></i> <a href="./resource/ichao_cv.pdf"><b>C.V.</b></a>  &nbsp; | &nbsp; 
                    <i class="ai ai-google-scholar-square ai-1x"></i> 
                    <a href="https://scholar.google.com/citations?user=0XSoTYMAAAAJ&hl=en"><b>Google Scholar</b></a> &nbsp; | &nbsp;
                <i class="fa fa-envelope fa-1x"></i> <a href="mailto: jdilyshen@gmail.com"><b>Email</b></a> &nbsp; 
                <!-- | &nbsp; -->
                <!-- <i class="fa fa-calendar"></i> <a href="https://jdily.github.io/vchci-deadlines/?sub=CG,HCI,ML,CV,MM" target="_blank"><b>VC/HCI Calendar</b></a> -->
            </p>
        </div>
    </div>

    <div class="row">
        <div class="twelve columns">
            <p style="font-size:16px; padding-top: 5px; font-weight: bold;">Publication</p>
        </div>
    </div>
    <div class="row publication">
        <div class="twelve columns">
        <table border="0" cellpadding="3" cellspacing="10">
            <tr>
                <td style="padding-right: 10px">
                    <img src="./resource/icon_colorization/vicon_colorization_image.png" style="vertical-align: text-top;" width="150" height="inherit"/>
                </td>
                <td>
                    <b>Palette-Based and Harmony-Guided Colorization for Vector Icons</b><br>
                    Miao Lin<sup>*</sup>, <u>I-Chao Shen</u><sup>*</sup>, Hsiao-Yuan Chin, Ruo-Xi Chen, Bing-Yu Chen (*: joint first authors)<br>
                    Computer Graphics Forum, Vol. 42, No. 7, (Proceedings of Pacific Graphics 2023 (PG 2023), Daejeon, Korea), 2023. <br>
                    <font style="color:#787878"> a palette-based colorization algorithm for vector icons without the need for rasterization. </font><br>
                    [<a href="./proj_site/icon_colorization.html">project page</a>]
		    [<a href="./resource/icon_colorizatin/PG23_icon_colorization.pdf">paper</a>]
		    [<a href="https://youtu.be/7aehJfJZxqA">video</a>]
                </td>
            </tr>
            <tr>
                <td style="padding-right: 10px">
                    <img src="./resource/data_proc_shape/proc_shape_img.png" style="vertical-align: text-top;" width="150" height="inherit"/>
                </td>
                <td>
                    <b>Data-guided Authoring of Procedural Models of Shapes</b><br>
                    Ishtiaque Hossain, <u>I-Chao Shen</u>, Takeo Igarashi, Oliver van Kaick<br>
                    Computer Graphics Forum, Vol. 42, No. 7, (Proceedings of Pacific Graphics 2023 (PG 2023), Daejeon, Korea), 2023. <br>
                    <font style="color:#787878"> a data-guided assistive system that can create a procedural model to replicate a collection of reference shapes. </font><br>
                    [<a href="./proj_site/data_proc_model.html">project page</a>]
		            [paper]
		            [code]
                </td>
            </tr>
            <tr>
                <td style="padding-right: 10px">
                    <img src="./resource/evicon/evicon_img.jpg" style="vertical-align: text-top;" width="150" height="inherit"/>
                </td>
                <td>
                    <b>EvIcon: Designing High-Usability Icon with Human-in-the-loop Exploration and IconCLIP</b><br>
                    <u>I-Chao Shen</u>, Fu-Yin Cherng, Takeo Igarashi, Wen-Chieh Lin, Bing-Yu Cheng <br>
                    Computer Graphics Forum 2023 <br>
                    <font style="color:#787878">an assistive system for designing high usability icons with a novel icon-specific visual-language model.</font><br>
                    [<a href="./proj_site/evicon_proj.html">project page</a>]
		    [<a href="./resource/evicon/EvIcon_cgf_final.pdf">paper</a>]
		    [<a href="https://youtu.be/uQucAoHd9Gg">video</a>]
                    [<a href="https://arxiv.org/abs/2305.17609">arxiv</a>]
                </td>
            </tr>
            <tr>
                <td style="padding-right: 10px">
                    <img src="./resource/360mvsnet/360mvsnet_thumb.png" style="vertical-align: text-top;" width="150" height="inherit"/>
                </td>
                <td>
                    <b>360MVSNet: Deep Multi-view Stereo Network with 360&#176 Images for Indoor Scene Reconstruction</b><br>
                    Ching-Ya Chiu, Yu-Ting Wu, <u>I-Chao Shen</u>, Yung-Yu Chuang <br>
                    IEEE/CVF Winter Conference on Applications of Computer Vision (WACV) 2023 (Algorithm Track)<br>
                    <font style="color:#787878">a deep learning network for multi-view stereo with 360&#176 images.</font><br>
                    [<a href="./proj_site/360mvsnet_proj.html">project page</a>]
                    [<a href="./resource/360mvsnet/360mvsnet_main.pdf">paper</a>]
                    [<a href="./resource/360mvsnet/360mvsnet_supp.pdf">supplemental material</a>]
                </td>
            </tr>
            <tr>
                <td style="padding-right: 10px">
                    <img src="https://kevincosner.github.io/publications/Chung2022SFU/teaser.png" style="vertical-align: text-top;" width="150" height="inherit"/>
                </td>
                <td>
                    <b>StyleFaceUV: a 3D Face UV Map Generator for View-Consistent Face Image Synthesis</b><br>
                    Wei-Chieh Chung<sup>*</sup>, Jian-Kai Zhu<sup>*</sup>, <u>I-Chao Shen</u>, Yu-Ting Wu, Yung-Yu Chuang (*: joint first authors)<br>
                    to appear in British Machine Vision Conference (BMVC) 2022 <br>
                    <font style="color:#787878">an approach for generating detailed 3D faces using a pre-trained StyleGAN2 model.</font><br>
                    [<a href="./proj_site/stylefaceuv_proj.html">project page</a>]
                    [<a href="./resource/StyleFaceUV/StyleFaceUV_main.pdf">arxiv</a>]
                    [<a href="./resource/StyleFaceUV/StyleFaceUV_supp.pdf">supplemental material</a>]
                </td> 
            </tr>
            <tr>
                <td style="padding-right: 10px">
                    <img src="./resource/nerfin/nerfin_img.png" style="vertical-align: text-top;" width="150" height="inherit"/>
                </td>
                <td>
                    <b>NeRF-In: Free-Form Inpainting for Pretrained NeRF with RGB-D Priors</b><br>
                    <u>I-Chao Shen</u><sup>*</sup>, Hao-Kang Liu<sup>*</sup>, Bing-Yu Chen (*: joint first authors) <br>
                    arXiv, 2022 <br>
                    <font style="color:#787878">an optimization framework that enables users to remove unwanted objects or retouch undesired regions in a 3D scene represented by a pre-trained NeRF</font><br>
                    [<a href="./proj_site/nerfin_proj.html">project page</a>]
                    [<a href="https://arxiv.org/abs/2206.04901"">arxiv</a>]
                    [supplemental video]
                </td> 
            </tr>
            <tr>
                <td style="padding-right: 10px">
                    <img src="./resource/autopoly/autopoly_img.png" style="vertical-align: text-top;" width="150" height="inherit"/>
                </td>
                <td>
                    <b>AutoPoly: Predicting a Polygonal Mesh Construction Sequence from a Silhouette Image</b><br>
                    <u>I-Chao Shen</u>, Yu Ju (Edwin) Chen, Oliver van Kaick, Takeo Igarashi<br>
                        arXiv, 2022 <br>
                    <font style="color:#787878">a hybrid method that generates a polygonal mesh construction sequence from a silhouette image</font><br>
                    [<a href="./proj_site/autopoly_proj.html">project page</a>]
                    [<a href="https://arxiv.org/abs/2203.15233">arxiv</a>]
                </td> 
            </tr>
            <tr>
                <td style="padding-right: 10px">
                    <img src="./resource/oden/ODEN_fig.png" style="vertical-align: text-top;" width="150" height="inherit"/>
                </td>
                <td>
                    <b>ODEN: Live Programming for Neural Network Architecture Editing</b><br>
                    Chunqi Zhao, <u>I-Chao Shen</u>, Tsukasa Fukusato, Jun Kato, Takeo Igarashi<br>
                    In Proceedings of 26th International Conference on Intelligent User Interfaces (IUI 2022), Online, 2022.03.22-25.<br>
                    <font style="color:#787878">a intelligent neural network architecture editing system using live programming techniques</font><br>
                    [<a href="https://haremi.xyz/projects/oden/oden.html">project page</a>]
                        [<a href="./resource/iui2022/iui22-18.pdf">paper</a>]
                    [<a href="https://youtu.be/i4OGVdfgFxU">demo video</a>]
                    [presentation video]
                </td> 
            </tr>
            <tr>
                <td style="padding-right: 10px">
                    <img src="./resource/stylepart/stylepart_teaser.png" style="vertical-align: text-top;" width="150" height="inherit"/>
                </td>
                <td>
                    <b>StylePart: Image-based Shape Part Manipulation</b><br>
                    <u>I-Chao Shen</u>, Li-Wen Su, Yu-Ting Wu, Bing-Yu Chen<br>
                    arXiv, 2021 <br>
                    <font style="color:#787878">a shape-consistent latent mapping function that connects the image generative latent space and the 3D man-made shape attribute latent space</font><br>
                    [<a href="./proj_site/stylepart_proj.html">project page</a>]
                    [<a href="https://arxiv.org/abs/2111.10520">arxiv</a>]
                </td> 
            </tr>
            <tr>
                <td style="padding-right: 10px">
                    <img src="./images/mannequin_teaser.png" style="vertical-align: text-top;" width="150" height="inherit"/>
                </td>
                <td>
                    <b>Per Garment Capture and Synthesis for Real-time Virtual Try-on</b><br>
                    Toby Chong, <u>I-Chao Shen</u>, Nobuyuki Umetani, Takeo Igarashi  <br>
                    in proceeding of User Interface Software and Technology (UIST) 2021  <br>
                    <font style="color:#787878">a real-time virtual try-on using per garment capture and synthesis workflow</font><br>
                    [<a href="https://sites.google.com/view/deepmannequin">project page</a>]
                    [<a href="https://drive.google.com/file/d/1TtjZYr_bMtwu5YRlEPoI34aCuryyRkkj/view?usp=sharing">paper</a>]
                    [<a href="https://drive.google.com/file/d/1oBQhjAecSXSRLCyYKu1BocANtuRit1SC/view?usp=sharing">video</a>]
                    [<a href="https://arxiv.org/abs/2109.04654">arxiv</a>]
                    [<a href="https://www.u-tokyo.ac.jp/focus/en/press/z0508_00191.html">UTokyo english press</a>]
                    [<a href="https://sj.jst.go.jp/news/202202/n0209-01j.html">Science Japan (JST)</a>]
                </td> 
            </tr>
            <tr>
                <td style="padding-right: 10px">
                    <img src="./images/ddsb_thumbnail.png" style="vertical-align: text-top;" width="150" height="inherit"/>
                </td>
                <td>
                    <b>Data-driven Sketch Beautification with Neural Feature Representation</b><br>
                    <u>I-Chao Shen</u> <br>
                    IEEE Computer Graphics and Applications (CG&A) 2021 <br>
                    <font style="color:#787878">a data-driven approach for beautifying freehand sketches</font><br>
                    [<a href="./proj_site/ddsb_proj.html">project page</a>]
                    [<a href="../resource/ddsb/ddsb_cga.pdf">paper</a>]
                </td> 
            </tr>
            <tr>
                <td style="padding-right: 10px">
                    <img src="./images/hpg21_thumb.png" style="vertical-align: text-top;" width="150" height="inherit"/>
                </td>
                <td>
                    <b>Multi-Resolution Shared Representative Filtering for Real-Time Depth Completion</b><br>
                    Yu-Ting Wu, Tzu-Mao Li, <u>I-Chao Shen</u>, Hong-Shiang Lin, Yung-Yu Chuang  <br>
                    High-Performance Graphics (HPG) 2021  <br>
                    <font style="color:#787878">a real-time depth completion algorithm which can effectively handle large missing regions of depth maps</font><br>
                    [<a href="https://kevincosner.github.io/publications/Wu2021MSR/index.html">project page</a>]
                    [<a href="https://kevincosner.github.io/publications/Wu2021MSR/paper.pdf">paper</a>]
                </td> 
            </tr>
            <tr>
                <td style="padding-right: 10px">
                    <img src="./images/clipgen_img.png" style="vertical-align: text-top;" width="150" height="inherit"/>
                </td>
                <td>
                    <b>ClipGen: A Deep Generative Model for Clipart Vectorization and Synthesis</b><br>
                    <u>I-Chao Shen</u>, Bing-Yu Chen  <br>
                       Transaction on Visualization and Computer Graphics (TVCG), 2021 <br>
                    <font style="color:#787878">a novel deep learning-based approach for automatically vectorizing and synthesizing the clipart of man-made objects</font><br>
                    [<a href="./proj_site/clipgen_proj.html">project page</a>]
                    [<a href="../resource/clipgen/ClipGen_tvcg_final.pdf">paper</a>]
                    [<a href="http://arxiv.org/abs/2106.04912">arxiv</a>]
                </td> 
            </tr>
            <tr>
                <td style="padding-right: 10px">
                    <img src="./images/clipflip.png" style="vertical-align: text-top;" width="150" height="inherit"/>
                </td>
                <td>
                    <b> ClipFlip : Multi-view Clipart Design</b><br>
                    <u>I-Chao Shen</u>, Kuan-Hung Liu, Li-Wen Su, Yu-Ting Wu, Bing-Yu Chen<br>
                    Computer Graphics Forum, Volume 40, Issue 1, Feb 2021 <br>
                    <font style="color:#787878">an assistive system for clipart design by providing visual scaffolds from the unseen viewpoints</font><br>
                    [<a href="./proj_site/clipflip_proj.html">project page</a>]
                    [<a href="../resource/clipflip/clipflip_final_paper.pdf">paper</a>]
                    [<a href="../resource/clipflip/clipflip_supplemental_final.pdf">supplemental material</a>]
                    <!-- [<a href="https://onlinelibrary.wiley.com/doi/full/10.1111/cgf.14190">publisher version</a>]    -->
                    [<a href="http://arxiv.org/abs/2008.12933">arxiv</a>]
                </td> 
            </tr>           
            <tr>
                <td style="padding-right: 10px">
                    <img src="./images/ganui_img.png" style="vertical-align: text-top;" width="150" height="inherit"/>
                </td>
                <td>
                    <b> Interactive Optimization of Generative Image Modeling using Sequential Subspace Search and Content-based Guidance </b><br>
                    Toby Chong Long Hin<sup>*</sup>, <u>I-Chao Shen</u><sup>*</sup>, Issei Sato, Takeo Igarashi (*: joint first authors) <br>
                    Computer Graphics Forum, Volume 40, Issue 1, Feb 2021 <br>
                    <font style="color:#787878">a human-in-the-optimization method that allows users to directly explore and search the latent vector space of generative image modeling</font><br>
                    [<a href="./proj_site/ganui_proj.html">project page</a>]
                    [<a href="../resource/ganui/GANUI_cgf_final.pdf">paper</a>]          
                    <!-- [<a href="https://onlinelibrary.wiley.com/doi/full/10.1111/cgf.14188">publisher version</a>]  -->
                    [<a href="http://arxiv.org/abs/1906.09840">arxiv</a>]
                </td> 
            </tr>       
            <tr>
                <td style="padding-right: 10px">
                    <img src="./images/MOAI_real.png" style="vertical-align: text-top;" width="150" height="inherit"/>
                </td>
                <td>
                    <b> ZomeFab: Cost-effective Hybrid Fabrication with Interior Zometool Structure</b><br>
                    <u>I-Chao Shen</u>, Ming-Shiuan Chen, Chun-Kai Huang, Bing-Yu Chen  <br>
                    Computer Graphics Forum, Volume 39, Issue 1, Feb 2020 <br>
                    <font style="color:#787878">a hybrid 3D fabrication method that combines 3D printing and the Zometool construction set to achieve compact fabrication</font><br>
                    [<a href="./proj_site/zomeFab_proj.html">project page</a>]
                    [<a href="../resource/zomeFab_cgf2019/zomeFab_cgf_final.pdf">paper</a>]
                    <!-- [<a href="https://onlinelibrary.wiley.com/doi/full/10.1111/cgf.13805">publisher version</a>]  -->
                    [<a href="http://arxiv.org/abs/1906.09787">arxiv</a>]
                </td> 
            </tr>     
            <tr>
                <td style="padding-right: 10px">
                    <img src="./images/transfer_rl_rep_img.png" style="vertical-align: text-top;" width="150" height="inherit"/>
                </td>
                <td>
                    <b>Transferring Deep Reinforcement Learning with Adversarial Objective and Augmentation</b><br>
                    <u>I-Chao Shen</u>, Shu-Hsuan Hsu, Bing-Yu Chen  <br>
                    to appear in IJCAI-PRICAI 2020 Workshop on Knowledge Based Reinforcement Learning (KBRL) <br>
                    <font style="color:#787878">a semi-supervised transfer learning method for deep reinforcement learning</font><br>
                    [<a href="../resource/IJCAI_KBRL_RL_transfer.pdf">paper</a>][<a href="http://arxiv.org/abs/1809.00770">arXiv</a>]
                    [<a href="https://www.youtube.com/watch?v=zYo02n9c5YY">present video</a>]
                </td> 
            </tr>   
            <tr>
                <td style="padding-right: 10px">
                    <img src="https://people.cs.nctu.edu.tw/~liweichan/placeholders/project_icons/director360_icon.png" style="vertical-align: text-top;" width="150" height="inherit"/>
                </td>
                <td>
                    <b>Director-360: Introducing Camera Handling to 360 Cameras</b><br>
                    Hao-Juan Huang, <u>I-Chao Shen</u>, Liwei Chan  <br>
                    in proceeding of MobileHCI 2020 <br>
                    <!-- <font style="color:#D3D3D3">a semi-supervised transfer learning method for deep reinforcement learning</font><br> -->
                    [<a href="https://dl.acm.org/doi/10.1145/3379503.3403550">paper</a>]
                </td> 
            </tr>   
            <tr>
                <td style="padding-right: 10px">
                    <img src="./images/sig18_vec.jpg" style="vertical-align: text-top;" width="150" height="inherit"/>
                </td>
                <td>
                    <b>Perception-Driven Semi-Structured Boundary Vectorization</b><br>
                    Shayan Hoshyari, Edoardo A. Dominici, Alla Sheffer, Nathan Carr, Duygu Ceylan,  <br> Zhaowen Wang, <u>I-Chao Shen</u> <br>
                    ACM Transaction on Graphics (Proceedings of SIGGRAPH 2018)<br> 
                    <font style="color:#787878">a boundary vectorization approach leverages human perception of shapes to
                        generate vector images consistent with viewer expectations</font><br>
                    [<a href="http://www.cs.ubc.ca/labs/imager/tr/2018/PerceptionDrivenVectorization/">Project Page</a>]
                    [<a href="https://drive.google.com/open?id=1X_vwr2yhpMqxd8TTXHwQqkte_TpNKrbD">Paper</a>]
                    [<a href="./bibs.html#sig18_vec">bib</a>]
                </td> 
            </tr>  
            <tr>
                <td style="padding-right: 10px">
                    <img src="./images/17_PG_360video.jpg" style="vertical-align: text-top;" width="150" height="inherit"/>
                </td>
                <td>
                    <b>High-resolution 360 Video Foveated Stitching for Real-time VR</b><br>
                    Wei-Tse Lee*, Hsin-I Chen*, Ming-Shiuan Chen, <u>I-Chao Shen</u>, Bing-Yu Chen (*: joint first authors) <br>
                    Computer Graphics Forum (Proceedings of Pacific Graphics 2017) <br> 
                    <font style="color:#787878">a real-time 360◦ video foveatedstitching framework</font><br>
                    [<a href="https://drive.google.com/open?id=1S7E5O52dTOK_JRAg_EnqzQjwWNTIJEWN">Paper</a>]
                    [<a href="./resource/PG17_360/pg_present.pdf">Slide</a>]
                    [<a href="./bibs.html#pg16_retarget">bib</a>]
                </td> 
            </tr>  
            <tr>
                <td style="padding-right: 10px">
                    <img src="./images/16_SIGGRAPHAsia_ShapeNetSeg.jpg" style="vertical-align: text-top;" width="150" height="inherit"/>
                </td>
                <td>
                    <b> A Scalable Active Framework for Region Annotation in 3D Shape Collections</b><br>
                    Li Yi, Vladimir G. Kim, Duygu Ceylan, <u>I-Chao Shen</u>, Mengyan Yan, Hao Su, Cewu Lu, Qixing Huang, Alla Sheffer, Leonidas Guibas <br> ACM Transactions on Graphics (Proceedings of SIGGRAPH Asia 2016) <br> 
                    <font style="color:#787878">a novel active learning method capable of enriching massive geometric datasets with accurate semantic region annotations</font><br>
                    [<a href="http://web.stanford.edu/~ericyi/project_page/part_annotation/index.html">Project page</a>] 
                    [<a href="https://drive.google.com/open?id=1cYR37vrKHXSkEVBKC7eEyr1MVRndZqNx">Paper</a>]
                    [<a href="http://web.stanford.edu/~ericyi/papers/part_annotation_16_supplemental.pdf">Supplemental</a>]
                    [<a href="./bibs.html#siga16_active/">bib</a>]
                </td> 
            </tr>    
            <tr>
                <td style="padding-right: 10px">
                    <img src="./images/16-PG-Retarget.png" style="vertical-align: text-top;" width="150" height="inherit"/>
                </td>
                <td>
                    <b>Retargeting 3D Objects and Scenes with a General Framework</b><br>
                    Chun-Kai Huang, Yi-Ling Chen, <u>I-Chao Shen</u>, Bing-Yu Chen <br> Computer Graphics Forum (Proceedings of Pacific Graphics 2016) <br>
                    <font style="color:#787878">an interactive method suitable for retargeting both 3D objects and scenes</font><br>
                    [<a href="http://www.cmlab.csie.ntu.edu.tw/~chinkyell/project/regtargeting.html">Project page</a>]
                    [<a href="https://drive.google.com/open?id=1TLfE4O65oYSmp399Pzwgg03kOKSfnnbU">Paper</a>]
                    [<a href="https://www.dropbox.com/s/q2i63fr5yrkkbfc/PG2016-SceneEditing-SuppMat-fin.pdf?dl=0">Supplemental</a>]
                    [<a href="https://www.dropbox.com/s/vzaxe5hlsjra2wr/pg16-sceneRetargeting_slide.pptx?dl=0">Slide</a>]
                    [<a href="./bibs.html#pg16_retarget">bib</a>]
                </td> 
            </tr>   
            <tr>
                <td style="padding-right: 10px">
                    <img src="./images/PG2015-hrs.png" style="vertical-align: text-top;" width="150" height="inherit"/>
                </td>
                <td>
                    <b>Data-driven Handwriting Synthesis in a Conjoined Manner</b><br>
                    Hsin-Yi Chen, Tse-Ju Lin, <u>I-Chao Shen</u>, Bing-Yu Chen <br> Computer Graphics Forum (Proceedings of Pacific Graphics 2015) <br>
                    <font style="color:#787878">a novel method for synthesizing handwritten text according to the writer’s style while considering characters’ conjoined property </font><br>   
                    [<a href="http://graphics.csie.ntu.edu.tw/~fensi/projects/handwriting/">Project page</a>]
                    [<a href="https://drive.google.com/open?id=1EIh2FGLuRWbQQ5AhgHNnNmEs-GTyHja8">Paper</a>]
                    [<a href="http://graphics.csie.ntu.edu.tw/~fensi/projects/handwriting/PG2015-hrs.pptx">Slide</a>]
                    [<a href="./bibs.html#pg15_handwriting">bib</a>]
                </td> 
            </tr>    
            <tr>
                <td style="padding-right: 10px">
                    <img src="./images/2015TMM-GF.png" style="vertical-align: text-top;" width="150" height="inherit"/>
                </td>
                <td>
                    <b>Gestalt Rule Feature Points</b><br>
                    <u>I-Chao Shen</u>, Wen-Huang Cheng <br> IEEE Transactions on Multimedia (TMM), volume 17, number 4, page 526-537, April 2015.<br>
                    <font style="color:#787878">a new approach for detecting reliable visual features from images in different visual styles (e.g., a photo and a painting) </font><br>
                    [<a href="https://drive.google.com/open?id=1OGuar_Old21Rw8Q3Bbnsrsc-0xWiQn99">Paper</a>]
                    [<a href="http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=7047900&queryText%3Dgestalt+rule+feature+point">Digital Library</a>]
                    [<a href="./bibs.html#tmm15_gestalt">bib</a>]
                </td> 
            </tr>  
            <tr>
                <td style="padding-right: 10px">
                    <img src="./images/TVCG14-StereoSyn.png" style="vertical-align: text-top;" width="150" height="inherit"/>
                </td>
                <td>
                    <b>Geometrically Consistent Stereoscopic Image Editing using Patch-based Synthesis</b><br>
                    Sheng-Jie Luo, Ying-Tse Sun, <u>I-Chao Shen</u>, Bing-Yu Chen, Yung-Yu Chuang, <br> IEEE Transactions on Visualization and Computer Graphics (TVCG), Vol.21, No. 1, pp. 56-67, January 2015. <br>
                    <font style="color:#787878">a patch-based synthesis framework for stereoscopic image editing problems, including depth-guided texture synthesis, stereoscopic NPR, paint by depth, content adaptation, and 2D to 3D
                    conversion </font><br>
                    [<a href="http://www.cmlab.csie.ntu.edu.tw/~forestking/research/TVCG14-StereoSyn/">Project Page</a>]
                    [<a href="https://drive.google.com/open?id=1VCTQkPdfqdUWPA-zKv2muY-beFusefCR">Paper</a>]
                    [<a href="http://ieeexplore.ieee.org/xpl/articleDetails.jsp?arnumber=6824802">Digital Library</a>]
                    [<a href="./bibs.html#tvcg13_stereo_patch">bib</a>]
                </td> 
            </tr> 
            <tr>
                <td style="padding-right: 10px">
                    <img src="./images/PG2013-Skeleton.png" style="vertical-align: text-top;" width="150" height="inherit"/>
                </td>
                <td>
                    <b>Stroke-guided Image Synthesis for Skeletal Structure Editing</b><br>
                    Sheng-Jie Luo, Chin-Yu Lin, <u>I-Chao Shen</u>, Bing-Yu Chen, <br> Computer Graphics Forum (Pacific Graphics 2013) <br>
                    <font style="color:#787878">a technique for synthesizing image objects with different skeletal structures while respecting to an input image object</font><br>
                    [<a href="http://www.cmlab.csie.ntu.edu.tw/~forestking/research/PG13-SkeletalEditing/">Project Page</a>]
                    [<a href="https://drive.google.com/open?id=1qAESxb4ZE6XDf1JRgpEQo_qjzv5OrFjr">Paper</a>]
                    [<a href="http://www.cmlab.csie.ntu.edu.tw/~forestking/research/PG13-SkeletalEditing/resources/pg13_skeleton_fin.pptx">Slide</a>]
                    [<a href="http://diglib.eg.org/EG/DL/CGF/volume32/issue7">Digital Library</a>]
                    [<a href="./bibs.html#pg13_stroke">bib</a>]
                </td> 
            </tr> 
            <tr>
                <td style="padding-right: 10px">
                    <img src="./images/SIGGRAPHASIA2012-stereocloning.png" style="vertical-align: text-top;" width="150" height="inherit"/>
                </td>
                <td>
                    <b>Perspective-Aware Warping for Seamless Stereoscopic Image Cloning</b><br>
                    Sheng-Jie Luo, <u>I-Chao Shen</u>, Bing-Yu Chen, Wen-Huang Cheng, Yung-Yu Chuang, <br> SIGGRAPH ASIA 2012 <br>
                    <font style="color:#787878">a novel technique for seamless stereoscopic image cloning, which performs both shape adjustment and color blending</font><br>
                    [<a href="http://www.cmlab.csie.ntu.edu.tw/~forestking/research/SIGA12-StereoCloning/">Project Page</a>]
                    [<a href="https://drive.google.com/open?id=1leH6uRjaBZa9oyelk0FVcE3UaTWGI72T">Paper</a>]
                    [<a href="http://doi.acm.org/10.1145/2366145.2366201">Digital Library</a>]
                    [<a href="./bibs.html#siga12_cloning">bib</a>]
                </td> 
            </tr>   
        </table>
        </div>
    </div>

    <hr> 
    <div class="row">
        <div class="twelve columns">
            <p style="font-size:16px; padding-top: 5px; font-weight: bold;">Short Paper, Poster, and Demo</p>
        </div>
    </div>
    <div class="row publication">
        <div class="twelve columns">
        <table border="0" cellpadding="3" cellspacing="10">
	    <tr>
                <td style="padding-right: 10px">
                    <img src="./resource/nebuta/nebuta2.png" style="vertical-align: text-top;" width="100" height="inherit"/>
                </td>
                <td>
                    <b>Computational Design of Nebuta-like Paper-on-Wire Artworks</b><br>
		    Naoki Agata, Anran Qi, Yuta Noma, <u>I-Chao Shen</u>, Takeo Igarashi<br>
                    SIGGRAPH 2023 Poster <br>
                    [<a href="./resource/nebuta/nebuta_siggraph23_poster.pdf">paper</a>]
	            [<a href="./resource/nebuta/nebuta_poster_design.pdf">poster</a>]
                </td> 
            </tr>  
	    <tr>
                <td style="padding-right: 10px">
                    <img src="./resource/icon_colorization/vicon_colorization_image.png" style="vertical-align: text-top;" width="100" height="inherit"/>
                </td>
                <td>
                    <b>Palette-Based Colorization for Vector Icons</b><br>
		    Miao Lin, <u>I-Chao Shen</u>, Hsiao-Yuan Chin, Ruo-Xi Chen, Bing-Yu Chen<br>
                    SIGGRAPH 2023 Poster <br>
                    [<a href="./resource/icon_colorization/vicon_colorization_siggraph23poster.pdf">paper</a>]
	            [<a href="./resource/icon_colorization/vicon_colorization_poster_design.pdf">poster</a>]
                </td> 
            </tr>  
            <tr>
                <td style="padding-right: 10px">
                    <img src="./resource/stencil_art/siga2022_stencil_art.png" style="vertical-align: text-top;" width="100" height="inherit"/>
                </td>
                <td>
                    <b>OVERPAINT: Automatic Multi-Layer Stencil Generation without Bridges</b><br>
	            Yuta Fukushima, Anran Qi, <u>I-Chao Shen</u>, Takeo Igarashi<br>
                    SIGGRAPH ASIA 2022 Technical Communication <br>
                    [<a href="./resource/stencil_art/Stencil_Generation_siga2022_tcom.pdf">paper</a>]
                </td> 
            </tr>  
            <tr>
                <td style="padding-right: 10px">
                    <img src="./images/img2img_translate.png" style="vertical-align: text-top;" width="100" height="inherit"/>
                </td>
                <td>
                    <b>Guided Image Weathering using Image-to-Image Translation</b><br>
                    Li-Yu Chen, <u>I-Chao Shen</u>, Bing-Yu Chen<br>
                   SIGGRAPH ASIA 2021 Technical Communication <br>
                   [<a href="./resource/sa21_weathering/SA21_TC_Weathering.pdf">paper</a>]
                   [<a href="https://youtu.be/EqRucsDFzOQ">presentation video</a>]
                </td> 
            </tr>   
            <tr>
                <td style="padding-right: 10px">
                <img src="./images/mannequin_teaser.png" style="vertical-align: text-top;" width="100" height="inherit"/>
                </td>
                <td>
                    <b>Real-time Image-based Virtual Try-on with Measurement Garment</b><br>
                    Toby Chong, <u>I-Chao Shen</u>, Yunfei Qian, Nobuyuki Umetani, Takeo Igarashi<br>
                    SIGGRAPH ASIA 2021 Emerging Technologies <br>
                   [<a href="./resource/sa21_etech_mannequin/Mannequin_sigasia_etech2021.pdf">paper</a>]
                </td> 
            </tr>   
            <tr>
                <td style="padding-right: 10px">
                    <img src="./images/PG2012-Disparity.png" style="vertical-align: text-top;" width="100" height="inherit"/>
                </td>
                <td>
                    <b>User-Assisted Disparity Maps</b><br>
                    Hsin-Yi Chen, Yi-Shan Lin, <u>I-Chao Shen</u>, Sheng-Jie Luo, Wen-Huang Cheng, Bing-Yu Chen,<br> Pacific Graphics 2012 Short Paper <br>
                    <font style="color:#787878">an intuitive and efficient system for correcting the artifacts and noises caused by imperfect disparity estimation</font><br>
                    [<a href="http://www.cmlab.csie.ntu.edu.tw/project/udm/">project Page</a>]
                    [<a href="https://drive.google.com/open?id=1x1rJwraWb0pwEM0OwuIOsYez-XuplIHg">paper</a>]
                    [<a href="./bibs.html#pg12_disparity">bib</a>]
                </td> 
            </tr>     
        </table>
        </div>
    </div> 

    <hr> 
    <div class="row">
        <div class="twelve columns">
            <p style="font-size:16px; padding-top: 5px; font-weight: bold;">Domestic (Japan) Papers and Posters</p>
        </div>
    </div>
    <div class="row publication">
        <div class="twelve columns">
        <table border="0" cellpadding="3" cellspacing="10">
            <tr>
                <td>
                    <b>「ねぶた風紙細工」をデザインするためのアルゴリズム</b>, Naoki Agata, Anran Qi, Yuta Noma, <u>I-Chao Shen</u>, Takeo Igarashi. VC 2023 Paper (ロング発表) [paper]
                </td> 
            </tr>  
            <tr>
                <td>
                    <b>「タイポグラフィに特化した視覚言語モデル</b>, 裕貴 立川, 健夫 五十嵐, 裕己 小山, 奕超 沈, 安然 祁 and アリエル シャミール. VC 2023 Paper (ショート発表) [paper]
                </td> 
            </tr>  
            <tr>
                <td>
                    <b>OVERPAINT: 橋を用いない多層ステンシルの自動生成</b>, Yuta Fukushima, Anran Qi, <u>I-Chao Shen</u>, Takeo Igarashi. VC 2022 Poster [<a href="./resource/stencil_art/Stencil_Generation_siga2022_tcom.pdf">paper</a>] [<a href="./resource/stencil_art/YutaFukushima_poster.pdf">poster</a>]
                </td> 
            </tr>  
        </table>
        </div>
    </div>

    <!-- <div class="row">
        <div class="twelve columns">
            <h3>Misc</h3>
        </div>
    </div> -->
    <!-- <div class="row publication">
        <div class="twelve columns">
        <table border="0" cellpadding="3" cellspacing="10">
            <tr>
                <td style="padding-right: 10px">
                    <img src="" style="vertical-align: text-top;" width="150" height="inherit"/>
                </td>
                <td>
                    <b>All-in-one latex template</b><br>
                    a latex paper template that supports various conferences across research fields including computer graphics, computer vision, and hci.<br>
                    [<a href="https://github.com/jdily/all_conf_template">code</a>]
                </td> 
            </tr>  
            <tr>
                <td style="padding-right: 10px">
                    <img src="./images/tex_deform_10.png" style="vertical-align: text-top;" width="150" height="inherit"/>
                </td>
                <td>
                    <b>Texturing and Deforming Meshes with Casual Images</b><br>
                    <u>I-Chao Shen</u>, Yi-Hau Wang, Yu-Mei Chen, Bing-Yu Chen<br>
                    [<a href="https://arxiv.org/abs/1809.03144">arXiv</a>]
                </td> 
            </tr>
        </table>
        </div>
    </div> -->

        <!-- footer
   ================================================== -->
        <footer>
            <div class="row">
                <div class="twelve columns">
                    <ul class="copyright">
                        <!--<li>Last modified: Dec 27, 2021</li>-->
                    </ul>
                </div>
            </div>
        </footer>
        <!-- Footer End-->
</body>

</html>
